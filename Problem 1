import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import torch
from torch.utils.data import TensorDataset, DataLoader

dia_file = "/content/diabetes (1).csv"
df = pd.read_csv(dia_file)

X = df.drop("Outcome", axis=1).values
y = df["Outcome"].values


X_train, X_val, y_train, y_val = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)


scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)

X_train_t = torch.tensor(X_train, dtype=torch.float32)
X_val_t   = torch.tensor(X_val,   dtype=torch.float32)
y_train_t = torch.tensor(y_train, dtype=torch.float32)
y_val_t   = torch.tensor(y_val,   dtype=torch.float32)


train_ds = TensorDataset(X_train_t, y_train_t)
val_ds   = TensorDataset(X_val_t,   y_val_t)

train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)
val_loader   = DataLoader(val_ds,   batch_size=64, shuffle=False)

import torch.nn as nn

class DiabetesMLP(nn.Module):
    def __init__(self, input_dim):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 16),
            nn.ReLU(),
            nn.Linear(16, 1),
            nn.Sigmoid()
        )
    def forward(self, x):
        return self.net(x)

from sklearn.metrics import accuracy_score, precision_recall_fscore_support

def train_model(model, train_loader, val_loader, epochs=100, lr=1e-3):
    criterion = nn.BCELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)

    history = {"train_loss": [], "val_loss": []}

    for epoch in range(epochs):
        model.train()
        train_loss = 0.0
        for xb, yb in train_loader:
            xb, yb = xb, yb.view(-1, 1)
            optimizer.zero_grad()
            out = model(xb)
            loss = criterion(out, yb)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * xb.size(0)
        train_loss /= len(train_loader.dataset)
        
        model.eval()
        val_loss = 0.0
        preds_list, true_list = [], []
        with torch.no_grad():
            for xb, yb in val_loader:
                xb, yb = xb, yb.view(-1, 1)
                out = model(xb)
                val_loss += criterion(out, yb).item() * xb.size(0)

                preds = (out >= 0.5).float().cpu().numpy().ravel()
                preds_list.extend(preds)
                true_list.extend(yb.cpu().numpy().ravel())

        val_loss /= len(val_loader.dataset)

        history["train_loss"].append(train_loss)
        history["val_loss"].append(val_loss)

        print(f"Epoch {epoch+1}/{epochs} | Train {train_loss:.4f} | Val {val_loss:.4f}")

    
    acc = accuracy_score(true_list, preds_list)
    prec, rec, f1, _ = precision_recall_fscore_support(
        true_list, preds_list, average="binary"
    )

    return history, acc, prec, rec, f1
input_dim = X_train.shape[1]
model = DiabetesMLP(input_dim)

history, acc, prec, rec, f1 = train_model(
    model, train_loader, val_loader,
    epochs=100, lr=1e-3
)

import matplotlib.pyplot as plt

plt.figure(figsize=(7,5))
plt.plot(history["train_loss"], label="Train Loss")
plt.plot(history["val_loss"], label="Validation Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Diabetes MLP Training vs Validation Loss")
plt.legend()
plt.grid(alpha=0.3)
plt.show()
